
\chapter{Συμπεράσματα και Μελλοντικές Επεκτάσεις}
\label{chapter:end}

\section{Συμπεράσματα}
\label{section:conclusion}

Συνοψίζοντας θα περιγράψουμε το τελικό σύστημα που υλοποιήσαμε καθώς και τα αποτελέσματα των μετρήσεων που κάναμε προκειμένου να ελέγξουμε την απόδοση και αξιοπιστία του συστήματός μας.

Η υλοποίηση, μπορεί να χωριστεί σε τέσσερα διακριτά υποσυστήματα. Έναν server που φιλοξενεί το api του συστήματός μας. Μέσω αυτού γίνεται η επικοινωνία με τα υπόλοιπα υποσυστήματα και η μεταφορά της αποθηκευμένης πληροφορίας εφόσον το εισερχόμενο αίτημα διαθέτει τα απαραίτητα κλειδιά.

Έναν ή περισσότερους schedulers που είναι υπεύθυνοι για τον έλεγχο αποθηκευμένων στη βάση URLs. Αυτοί είναι προγραμματισμένοι να τρέχουν με συγκεκριμένο ρυθμό αιτήματα, προς τα συστήματα που θέλουμε κάθε φορά, να ελέγχουμε. Πέραν αυτού, είναι υπεύθυνοι για τον καθαρισμό της βάσης δεδομένων (mongo) από περιττές πληροφορίες και τη μεταφορά τους σε file storage βάση δεδομένων (Google Cloud Storage).

Στη συνέχεια ακολουθεί το Krosswalk. Αυτό είναι υπεύθυνο για τη μεταφορά logs της λειτουργίας του container που ελέγχουμε και την τροποποίηση των πόρων του συστήματος ανάλογα με τις εντολές που λαμβάνει από το Oracle. Βασική συνθήκη είναι το υπό μελέτη σύστημα να είναι και αυτό docker container. Το Krosswalk επικοινωνεί με μια Kafka ουρά από την οποία διαβάζει events από το topic updates και στέλνει events στο topic usages.

Το τελευταίο υποσύστημα είναι το Oracle το οποίο είναι υπεύθυνο για την αναγνώριση ανωμαλιών στη χρονοσειρά των αποκρίσεων που μαζεύει το Lychte κατά τη λειτουργία του. Για τον εντοπισμό των σημείων χρησιμοποιούμε τον αλγόριθμο RePAD2. Μόλις βρούμε κάποιο σημείο που αποκλίνει από τη φυσιολογική λειτουργία του συστήματος, διαβάζουμε από την Kafka ουρά, και πιο συγκεκριμένα από το topic usages το τελευταίο event που έχει έρθει για το API που ελέγχουμε. Ανάλογα με τις τιμές κατανάλωσης CPU και RAM που έχουμε, στέλνουμε event στο topic updates προκειμένου να τα τροποποιήσει αντίστοιχα το Krosswalk.

Για να ελέγξουμε την απόδοση και την αξιοπιστία του συστήματος, κάναμε κάποιες μετρήσεις. Αρχικά μελετήσαμε τη λειτουργία των schedulers που υλοποιήσαμε. Ξεκινώντας με ένα σχετικά μικρό πλήθος αιτημάτων που τρέχουν παράλληλα (100 στο πλήθος), και αυξάνοντας
τα σταδιακά (φτάσαμε στα 5.000), είδαμε ότι η μέση απόκλιση του αναμενόμενου χρόνου εκτέλεσης των διάφορων αιτημάτων παραμένει χαμηλή, φτάνοντας μάλιστα
σε ορισμένες περιπτώσεις σε αρνητικές τιμές. Όσον αφορά στην κατανάλωση πόρων του υπολογιστικού συστήματος, παρατηρούμε ότι
αυξάνοντας το πλήθος των αιτημάτων που εκτελούνται παράλληλα από έναν scheduler, αυξάνονται, μετά από ένα ορισμένο σημείο, κατά πολύ οι απαιτήσεις του
συστήματος. Αυτό μας οδηγεί στο συμπέρασμα, ότι πάντα θα πρέπει να υπάρχουν διαθέσιμοι schedulers στους οποίους θα
μπορεί να γίνεται καταμερισμός των ενεργών αιτημάτων, ώστε να αποφεύγονται καταστάσεις υπερφόρτωσης του συστήματος.  

Τέλος πραγματοποιήσαμε μετρήσεις για να ελέγξουμε τη λειτουργία της αυτόματης τροποποιήσεις των πόρων ενός συστήματος που αποτελεί docker container. Εδώ παρατηρήσαμε ότι ο εντοπισμός ανώμαλων σημείων γίνεται επιτυχώς. Στα σημεία που έχουμε spikes στη χρονοσειρά των αποκρίσεων βρίσκουμε ανώμαλα σημεία τα οποία εξομαλύνονται σε επόμενες χρονικές στιγμές που έχουν δωθεί περισσότεροι διαθέσιμοι πόροι στο υπό μελέτη σύστημα. Μάλιστα όταν ο φόρτος στο σύστημα πέφτει και κατά συνέπεια οι τιμές των λαμβανομένων, από το σύστημα, αποκρίσεων μειώνονται γίνεται πάλι εντοπισμός ανώμαλων σημείων. Αυτή τη φορά η κατανάλωση του συστήματος είναι τέτοια που δεν απαιτείται η περαιτέρω τροποποίηση του υπό μελέτη συστήματος.

Αξίζει να αναφερθεί ότι σε αντίθεση με άλλα συστήματα (\cite{sinan}, \cite{reclaimer}) δεν απαιτείται μεγάλης διάρκειας offline training period, καθώς από την έβδομη εγγραφή και ύστερα ξεκινάει να λειτουργεί κανονικά ο αγλόριθμος εντοπισμού που χρησιμοποιήσαμε (RePAD2). Επίσης τα δεδομένα με τα οποία εκπαιδεύουμε τα μοντέλα μας δεν είναι labeled, καθιστώντας τα έτσι αμιγώς unsupervised και συνεπώς πιο απλά στην εφαρμογή τους.

\section{Μελλοντικές Επεκτάσεις}
\label{section:future_stuff}

Όπως είδαμε, το σύστημα Lychte που υπολοποιήσαμε στο πλαίσιο της διπλωματικής αυτής
εργασίας δουλεύει σε ένα αρκετά ικανοποιητικό επίπεδο, με τα αποτελέσματα των μετρήσεων που πραγματοποιήσαμε να το αποδεικνύουν.

Υπάρχει όμως ακόμα χώρος για βελτίωση. Όπως είδαμε, όταν το πλήθος των εξωτερικών συστημάτων που θέλουμε να ελέγχουμε
αυξάνεται θα πρέπει να αυξάνεται αντίστοιχα και το πλήθος των schedulers που λειτουργούν προς την εξυπηρέτηση αυτών. Μία λύση στο πρόβλημα αυτό, και για
την αποφυγή ύπαρξης καταστάσεων που ένας scheduler δυσλειτουργεί ή το υπολογιστικό σύστημα στο οποίο ζει δεν μπορεί να ικανοποιήσει
τις ανάγκες του ως προς τους πόρους που απαιτεί, είναι η αυτόματη ενημέρωση κάποιου admin, που διαχειρίζεται το σύστημα,
προκειμένου να δημιουργήσει και άλλους schedulers. Είναι σημαντικό ακόμα να ερευνηθεί στο πλαίσιο αυτό το κομμάτι της κύριας βάσης δεδομένων
που χρησιμοποιούμε. H παρούσα υλοποίηση αξιοποιεί τις δυνατότητες της MongoDB. Υπάρχουν όμως πλήθος άλλων
noSql βάσεων, όπως για παράδειγμα του Redis, η χρήση του οποίου θα μπορούσε να βελτιώσει την απόδοση και την ταχύτητα των
queries στη βάση. Ακόμα, θα μπορούσε να ερευνηθεί το κατά πόσο θα είχε νόημα ο συνδυασμός μίας κύριας και μίας δευτερεύουσας βάσης (πέραν αυτής του Google Cloud Storage),
που θα χρησιμοποιούνται από τις δύο διαφορετικές οντότητες του συστήματός μας, προκειμένου να διαμοιραστεί ο φόρτος των λειτουργιών που κατά βάση εκτελούν οι schedulers.

Ένας ακόμα τομέας στον οποίο υστερεί το σύστημα, είναι το περιορισμένο πλήθος των τύπων ελέγχου που μπορούμε
να κάνουμε. Σε μελλοντική έκδοση, θα μπορούσαμε να ενσωματώσουμε αιτήματα ελέγχου PORTS, TCP συνδέσεων, αποστολής μηνυμάτων μέσω του πρωτοκόλλου επικοινωνίας MQTT,
καθώς και ελέγχους συνδέσεων και αποστολής μηνυμάτων σε socket.io server. Επιπλέον, θα μπορούσαμε να επεκτείνουμε τα 
μέσα ενημέρωσης (σε περίπτωση προβληματος) των χρηστών. Το τωρινό σύστημα παρέχει δυνατότητες ενημέρωσης μέσω mail, αλλά θα μπορούσαμε ακόμα να επιτρέψουμε
τη σύνδεση άλλων μορφών επικοινωνίας, όπως είναι οι διάφορες messaging εφαρμογές (Slack, Discord). 

Μία ακόμα επέκταση που θα μπορούσαμε να κάνουμε σε επόμενο βήμα μας είναι η προσαρμογή του Krosswalk προκειμένου να μπορεί να χρησιμοποιηθεί και από άλλα
εργαλεία που προσφέρουν δυνατότητες containerisation εφαρμογών (Podman, Lxd, Containerd, Buildah). Μιας και πλέον ανάλογα εργαλεία έχουν όλο και μεγαλύτερη απήχηση, παρατηρείται συνεχής αύξηση και
βελτίωση των λειτουργιών που αυτά παρέχουν.

Πέρα από τη βελτίωση του backend του συστήματος, θα μπορούσαμε ακόμα να προσθέσουμε παραπάνω διαγράμματα,
αξιοποιώντας περαιτέρω τα αποθηκευμένα δεδομένα μας και δείχνοντας παραπάνω χρήσιμη πληροφορία στο χρήστη.